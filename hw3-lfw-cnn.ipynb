{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "This notebook creates 2 convolutional neural networks, 1 for aligned images and 1 for unaligned raw images.\n",
    "Predictions are then based on the network that provides the higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "seed = 3244\n",
    "np.random.seed(seed)\n",
    "\n",
    "h = 50  # height of image\n",
    "w = 37  # width of image\n",
    "aligned_h = h\n",
    "aligned_w = h\n",
    "\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data used for unaligned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load original data\n",
    "X = np.load('X_train.npy') # (996, 1850)\n",
    "y = np.load('y_train.npy') # (996, 1)\n",
    "\n",
    "# Split into training and validation set\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Load generated data for training set\n",
    "X_generated_train = np.load('X_train_generated_train.npy')\n",
    "y_generated_train = np.load('y_train_generated_train.npy')\n",
    "\n",
    "# Add generated data for training set to original training set\n",
    "X_train = np.concatenate([X_train, X_generated_train])\n",
    "y_train_raw = np.concatenate([y_train_raw, y_generated_train])\n",
    "\n",
    "# Load generated data for validation set\n",
    "X_generated_test = np.load('X_train_generated_test.npy')\n",
    "y_generated_test = np.load('y_train_generated_test.npy')\n",
    "\n",
    "# Concatenate with generated data for training set to get all generated data\n",
    "X_generated = np.concatenate([X_generated_train, X_generated_test])\n",
    "y_generated = np.concatenate([y_generated_train, y_generated_test])\n",
    "\n",
    "# Add all generated data to full training set\n",
    "X = np.concatenate([X, X_generated])\n",
    "y = np.concatenate([y, y_generated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data used for aligned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load original data\n",
    "X_aligned = np.load('X_train_aligned.npy')\n",
    "y_aligned = np.load('y_train_aligned.npy')\n",
    "\n",
    "# Split into training and validation set\n",
    "X_train_aligned, X_test_aligned, y_train_aligned_raw, y_test_aligned_raw = train_test_split(X_aligned, y_aligned, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Load generated data for training set\n",
    "X_generated_train_aligned = np.load('X_train_generated_train_aligned.npy')\n",
    "y_generated_train_aligned = np.load('y_train_generated_train_aligned.npy')\n",
    "\n",
    "# Add generated data for training set to original training set\n",
    "X_train_aligned = np.concatenate([X_train_aligned, X_generated_train_aligned])\n",
    "y_train_aligned_raw = np.concatenate([y_train_aligned_raw, y_generated_train_aligned])\n",
    "\n",
    "# Load generated data for validation set\n",
    "X_generated_test_aligned = np.load('X_train_generated_test_aligned.npy')\n",
    "y_generated_test_aligned = np.load('y_train_generated_test_aligned.npy')\n",
    "\n",
    "# Concatenate with generated data for training set to get all generated data\n",
    "X_generated_aligned = np.concatenate([X_generated_train_aligned, X_generated_test_aligned])\n",
    "y_generated_aligned = np.concatenate([y_generated_train_aligned, y_generated_test_aligned])\n",
    "\n",
    "# Add all generated data to full training set\n",
    "X_aligned = np.concatenate([X_aligned, X_generated_aligned])\n",
    "y_aligned = np.concatenate([y_aligned, y_generated_aligned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shapeData(data, h=h, w=w):\n",
    "    return data.reshape(data.shape[0], 1, h, w).astype('float32')\n",
    "\n",
    "def normalize(data):\n",
    "    return data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = normalize(shapeData(X))\n",
    "\n",
    "X_train = normalize(shapeData(X_train))\n",
    "X_test = normalize(shapeData(X_test))\n",
    "\n",
    "X_train_aligned = normalize(shapeData(X_train_aligned, h=aligned_h, w=aligned_w))\n",
    "X_test_aligned = normalize(shapeData(X_test_aligned, h=aligned_h, w=aligned_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One hot encode outputs, this is required for the CNN\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train_raw)\n",
    "y_test = np_utils.to_categorical(y_test_raw)\n",
    "\n",
    "y_train_aligned = np_utils.to_categorical(y_train_aligned_raw)\n",
    "y_test_aligned = np_utils.to_categorical(y_test_aligned_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"Baseline model with 1 convolution, 1 max pooling and 2 fully connected layers\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters = 32  # number of convolutional filters to use\n",
    "pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "kernel_size = (5, 5)  # convolution kernel size\n",
    "\n",
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model2():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Note: Keras does automatic shape inference.\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model3():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1],\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, h, w)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model4():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1), input_shape=(1, h, w)))\n",
    "    model.add(Convolution2D(64, 3, 3,  activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation=\"relu\")) # 4096\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def model5(h=h, w=w):\n",
    "    \"\"\"Final configuration of the convolutional neural network that we found to perform the best\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, input_shape=(1, h, w), border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='valid', activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network based on the raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 46, 33)    832         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 23, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32, 23, 16)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 19, 12)    51264       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 9, 6)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 64, 9, 6)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 3456)          0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           884992      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 7)             1799        dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 938887\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1572 samples, validate on 194 samples\n",
      "Epoch 1/40\n",
      "1572/1572 [==============================] - 17s - loss: 1.7082 - acc: 0.3925 - val_loss: 1.6483 - val_acc: 0.4278\n",
      "Epoch 2/40\n",
      "1572/1572 [==============================] - 17s - loss: 1.6634 - acc: 0.4097 - val_loss: 1.5915 - val_acc: 0.4278\n",
      "Epoch 3/40\n",
      "1572/1572 [==============================] - 16s - loss: 1.5312 - acc: 0.4650 - val_loss: 1.4077 - val_acc: 0.5155\n",
      "Epoch 4/40\n",
      "1572/1572 [==============================] - 16s - loss: 1.2731 - acc: 0.5668 - val_loss: 1.1647 - val_acc: 0.5876\n",
      "Epoch 5/40\n",
      "1572/1572 [==============================] - 17s - loss: 1.0353 - acc: 0.6457 - val_loss: 0.9633 - val_acc: 0.6701\n",
      "Epoch 6/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.8609 - acc: 0.7131 - val_loss: 0.8626 - val_acc: 0.7320\n",
      "Epoch 7/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.7385 - acc: 0.7525 - val_loss: 0.8072 - val_acc: 0.7216\n",
      "Epoch 8/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.6253 - acc: 0.7958 - val_loss: 0.6677 - val_acc: 0.7835\n",
      "Epoch 9/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.5028 - acc: 0.8391 - val_loss: 0.5522 - val_acc: 0.8351\n",
      "Epoch 10/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.4359 - acc: 0.8632 - val_loss: 0.4697 - val_acc: 0.8763\n",
      "Epoch 11/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.3792 - acc: 0.8779 - val_loss: 0.4771 - val_acc: 0.8763\n",
      "Epoch 12/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.3014 - acc: 0.9046 - val_loss: 0.4275 - val_acc: 0.8866\n",
      "Epoch 13/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.2738 - acc: 0.9148 - val_loss: 0.3800 - val_acc: 0.9175\n",
      "Epoch 14/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.2235 - acc: 0.9332 - val_loss: 0.4300 - val_acc: 0.8711\n",
      "Epoch 15/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.2279 - acc: 0.9268 - val_loss: 0.3867 - val_acc: 0.9072\n",
      "Epoch 16/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.2143 - acc: 0.9377 - val_loss: 0.3112 - val_acc: 0.9330\n",
      "Epoch 17/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.1782 - acc: 0.9402 - val_loss: 0.3117 - val_acc: 0.9227\n",
      "Epoch 18/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.1285 - acc: 0.9631 - val_loss: 0.3045 - val_acc: 0.9124\n",
      "Epoch 19/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0928 - acc: 0.9720 - val_loss: 0.3359 - val_acc: 0.9072\n",
      "Epoch 20/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.1041 - acc: 0.9688 - val_loss: 0.3386 - val_acc: 0.9227\n",
      "Epoch 21/40\n",
      "1572/1572 [==============================] - 19s - loss: 0.1026 - acc: 0.9714 - val_loss: 0.3636 - val_acc: 0.9175\n",
      "Epoch 22/40\n",
      "1572/1572 [==============================] - 18s - loss: 0.0770 - acc: 0.9790 - val_loss: 0.2898 - val_acc: 0.9124\n",
      "Epoch 23/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0790 - acc: 0.9752 - val_loss: 0.3683 - val_acc: 0.9021\n",
      "Epoch 24/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0615 - acc: 0.9828 - val_loss: 0.3173 - val_acc: 0.9278\n",
      "Epoch 25/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0490 - acc: 0.9879 - val_loss: 0.3451 - val_acc: 0.9278\n",
      "Epoch 26/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0690 - acc: 0.9816 - val_loss: 0.3423 - val_acc: 0.9278\n",
      "Epoch 27/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0454 - acc: 0.9892 - val_loss: 0.2991 - val_acc: 0.9433\n",
      "Epoch 28/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0564 - acc: 0.9866 - val_loss: 0.2950 - val_acc: 0.9433\n",
      "Epoch 29/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0491 - acc: 0.9860 - val_loss: 0.3210 - val_acc: 0.9175\n",
      "Epoch 30/40\n",
      "1572/1572 [==============================] - 19s - loss: 0.0617 - acc: 0.9796 - val_loss: 0.3275 - val_acc: 0.9175\n",
      "Epoch 31/40\n",
      "1572/1572 [==============================] - 18s - loss: 0.0782 - acc: 0.9746 - val_loss: 0.4033 - val_acc: 0.9124\n",
      "Epoch 32/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0623 - acc: 0.9803 - val_loss: 0.3152 - val_acc: 0.9278\n",
      "Epoch 33/40\n",
      "1572/1572 [==============================] - 19s - loss: 0.0361 - acc: 0.9892 - val_loss: 0.3031 - val_acc: 0.9381\n",
      "Epoch 34/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0310 - acc: 0.9898 - val_loss: 0.2954 - val_acc: 0.9381\n",
      "Epoch 35/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0237 - acc: 0.9955 - val_loss: 0.3112 - val_acc: 0.9278\n",
      "Epoch 36/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0428 - acc: 0.9879 - val_loss: 0.2906 - val_acc: 0.9433\n",
      "Epoch 37/40\n",
      "1572/1572 [==============================] - 17s - loss: 0.0286 - acc: 0.9943 - val_loss: 0.3040 - val_acc: 0.9330\n",
      "Epoch 38/40\n",
      "1572/1572 [==============================] - 18s - loss: 0.0388 - acc: 0.9885 - val_loss: 0.3593 - val_acc: 0.9330\n",
      "Epoch 39/40\n",
      "1572/1572 [==============================] - 18s - loss: 0.0308 - acc: 0.9930 - val_loss: 0.3087 - val_acc: 0.9330\n",
      "Epoch 40/40\n",
      "1572/1572 [==============================] - 16s - loss: 0.0242 - acc: 0.9924 - val_loss: 0.2706 - val_acc: 0.9433\n",
      "194/194 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9292760403689071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = baseline_model()\n",
    "# model = model1()\n",
    "# model = model2()\n",
    "# model = model3()\n",
    "# model = model4()\n",
    "model = model5()\n",
    "\n",
    "nb_epoch = 40\n",
    "batch_size = 50\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=batch_size, \n",
    "          verbose=1)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "f1_score(y_test_raw, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAFYCAYAAACLYe3IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wejWYYh9466wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c23beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 32,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1, 12,  0,  0,  0,  1],\n",
       "       [ 1,  1,  0, 80,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1, 15,  1,  0],\n",
       "       [ 0,  0,  0,  1,  0, 15,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0, 20]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_raw, y_pred)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network based on the aligned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 46, 46)    832         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 23, 23)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 32, 23, 23)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 19, 19)    51264       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 64, 9, 9)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 64, 9, 9)      0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 5184)          0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           1327360     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 7)             1799        dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1381255\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1514 samples, validate on 179 samples\n",
      "Epoch 1/40\n",
      "1514/1514 [==============================] - 29s - loss: 1.7094 - acc: 0.3791 - val_loss: 1.6246 - val_acc: 0.4358\n",
      "Epoch 2/40\n",
      "1514/1514 [==============================] - 25s - loss: 1.6151 - acc: 0.4207 - val_loss: 1.5508 - val_acc: 0.5363\n",
      "Epoch 3/40\n",
      "1514/1514 [==============================] - 25s - loss: 1.4214 - acc: 0.4775 - val_loss: 1.2642 - val_acc: 0.6313\n",
      "Epoch 4/40\n",
      "1514/1514 [==============================] - 24s - loss: 1.0548 - acc: 0.6328 - val_loss: 0.7550 - val_acc: 0.7318\n",
      "Epoch 5/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.7246 - acc: 0.7609 - val_loss: 0.5158 - val_acc: 0.8547\n",
      "Epoch 6/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.5428 - acc: 0.8170 - val_loss: 0.4106 - val_acc: 0.8603\n",
      "Epoch 7/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.4025 - acc: 0.8672 - val_loss: 0.3263 - val_acc: 0.8939\n",
      "Epoch 8/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.3103 - acc: 0.8996 - val_loss: 0.2473 - val_acc: 0.9050\n",
      "Epoch 9/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.2916 - acc: 0.9069 - val_loss: 0.2187 - val_acc: 0.9441\n",
      "Epoch 10/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.1993 - acc: 0.9412 - val_loss: 0.1876 - val_acc: 0.9497\n",
      "Epoch 11/40\n",
      "1514/1514 [==============================] - 27s - loss: 0.1520 - acc: 0.9538 - val_loss: 0.1625 - val_acc: 0.9497\n",
      "Epoch 12/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.1249 - acc: 0.9610 - val_loss: 0.1514 - val_acc: 0.9497\n",
      "Epoch 13/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.1102 - acc: 0.9630 - val_loss: 0.1283 - val_acc: 0.9497\n",
      "Epoch 14/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0979 - acc: 0.9703 - val_loss: 0.1262 - val_acc: 0.9609\n",
      "Epoch 15/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0929 - acc: 0.9709 - val_loss: 0.1403 - val_acc: 0.9553\n",
      "Epoch 16/40\n",
      "1514/1514 [==============================] - 22s - loss: 0.0905 - acc: 0.9736 - val_loss: 0.1258 - val_acc: 0.9665\n",
      "Epoch 17/40\n",
      "1514/1514 [==============================] - 22s - loss: 0.0686 - acc: 0.9795 - val_loss: 0.1110 - val_acc: 0.9609\n",
      "Epoch 18/40\n",
      "1514/1514 [==============================] - 22s - loss: 0.0606 - acc: 0.9841 - val_loss: 0.0930 - val_acc: 0.9721\n",
      "Epoch 19/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0477 - acc: 0.9828 - val_loss: 0.0762 - val_acc: 0.9553\n",
      "Epoch 20/40\n",
      "1514/1514 [==============================] - 26s - loss: 0.0370 - acc: 0.9894 - val_loss: 0.0618 - val_acc: 0.9777\n",
      "Epoch 21/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0256 - acc: 0.9934 - val_loss: 0.0833 - val_acc: 0.9777\n",
      "Epoch 22/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0317 - acc: 0.9901 - val_loss: 0.0920 - val_acc: 0.9721\n",
      "Epoch 23/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0417 - acc: 0.9861 - val_loss: 0.0974 - val_acc: 0.9665\n",
      "Epoch 24/40\n",
      "1514/1514 [==============================] - 22s - loss: 0.0273 - acc: 0.9947 - val_loss: 0.0869 - val_acc: 0.9665\n",
      "Epoch 25/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.0226 - acc: 0.9934 - val_loss: 0.0940 - val_acc: 0.9721\n",
      "Epoch 26/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0174 - acc: 0.9954 - val_loss: 0.1300 - val_acc: 0.9553\n",
      "Epoch 27/40\n",
      "1514/1514 [==============================] - 26s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.1126 - val_acc: 0.9609\n",
      "Epoch 28/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0324 - acc: 0.9861 - val_loss: 0.1031 - val_acc: 0.9665\n",
      "Epoch 29/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0265 - acc: 0.9927 - val_loss: 0.0984 - val_acc: 0.9777\n",
      "Epoch 30/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0642 - val_acc: 0.9777\n",
      "Epoch 31/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0118 - acc: 0.9987 - val_loss: 0.0949 - val_acc: 0.9609\n",
      "Epoch 32/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0102 - acc: 0.9974 - val_loss: 0.1146 - val_acc: 0.9665\n",
      "Epoch 33/40\n",
      "1514/1514 [==============================] - 27s - loss: 0.0309 - acc: 0.9881 - val_loss: 0.1246 - val_acc: 0.9665\n",
      "Epoch 34/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0987 - val_acc: 0.9721\n",
      "Epoch 35/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0204 - acc: 0.9927 - val_loss: 0.0736 - val_acc: 0.9777\n",
      "Epoch 36/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0154 - acc: 0.9974 - val_loss: 0.0585 - val_acc: 0.9777\n",
      "Epoch 37/40\n",
      "1514/1514 [==============================] - 24s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0502 - val_acc: 0.9777\n",
      "Epoch 38/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0108 - acc: 0.9980 - val_loss: 0.0788 - val_acc: 0.9721\n",
      "Epoch 39/40\n",
      "1514/1514 [==============================] - 25s - loss: 0.0088 - acc: 0.9987 - val_loss: 0.0710 - val_acc: 0.9777\n",
      "Epoch 40/40\n",
      "1514/1514 [==============================] - 23s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 0.9777\n",
      "179/179 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96189694376781454"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model5(h=aligned_h, w=aligned_w)\n",
    "\n",
    "model.fit(X_train_aligned, y_train_aligned, \n",
    "          validation_data=(X_test_aligned, y_test_aligned),\n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=batch_size, \n",
    "          verbose=1)\n",
    "\n",
    "y_pred_aligned = model.predict_classes(X_test_aligned)\n",
    "f1_score(y_test_aligned_raw, y_pred_aligned, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAFTCAYAAADhph0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzErESdnMrESclM3MSsRJ2cysRP4/+RZTHnj6Hs0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113b57c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  1,  0,  0,  0,  0],\n",
       "       [ 1,  0, 13,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 78,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1, 11,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1, 11,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 18]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_aligned_raw, y_pred_aligned)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a full model on the entire given dataset\n",
    "This includes generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_model = model5()\n",
    "full_model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a full model on the aligned images derived from the entire given dataset\n",
    "This includes generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_aligned = normalize(shapeData(X_aligned, h=aligned_h, w=aligned_w))\n",
    "y_aligned = np_utils.to_categorical(y_aligned)\n",
    "\n",
    "full_model_aligned = model5(h=aligned_h, w=aligned_w)\n",
    "full_model_aligned.fit(X_aligned, y_aligned, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the above 2 models to predict the labels of the given test set\n",
    "The test set with its images aligned are also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_given = normalize(shapeData(np.load('X_test.npy')))\n",
    "X_test_given_aligned = normalize(shapeData(np.load('X_test_aligned.npy'), h=aligned_h, w=aligned_w))\n",
    "\n",
    "classes_unaligned = full_model.predict_classes(X_test_given)\n",
    "classes_aligned = full_model_aligned.predict_classes(X_test_given_aligned)\n",
    "\n",
    "prob_unaligned = full_model.predict_proba(X_test_given)\n",
    "prob_aligned = full_model_aligned.predict_proba(X_test_given_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes_unaligned)\n",
    "print(classes_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieved from aligning the images, these are the indices of images where no face was detected\n",
    "idx_no_face = [25, 85, 104, 106, 125, 131, 180, 202, 211, 233, 238, 244, 279, 283, 304, 309]\n",
    "\n",
    "updated_classes = classes_aligned.tolist()\n",
    "updated_prob = prob_aligned.tolist()\n",
    "\n",
    "# Insert placeholder \"None\" to indicate that no class was derived for images with no face detected\n",
    "for i in idx_no_face:\n",
    "    updated_classes.insert(i, None)\n",
    "    updated_prob.insert(i, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the final class labels from an ensemble of the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_max(lst):\n",
    "    if lst:\n",
    "        return max(lst), lst.index(max(lst))\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "final_classes = []\n",
    "\n",
    "# Find the predicted class with the highest probability from the 2 model predictions\n",
    "for idx, (unaligned_prob, aligned_prob) in enumerate(zip(prob_unaligned, updated_prob)):\n",
    "    unaligned_highest_prob, unaligned_class = get_max(unaligned_prob.tolist())\n",
    "    aligned_highest_prob, aligned_class = get_max(aligned_prob)\n",
    "    \n",
    "    if aligned_highest_prob is None or unaligned_highest_prob > aligned_highest_prob:\n",
    "        final_classes.append(unaligned_class)\n",
    "    elif aligned_highest_prob >= unaligned_highest_prob:\n",
    "        final_classes.append(aligned_class)\n",
    "    else:\n",
    "        print(idx, unaligned_highest_prob, unaligned_class, aligned_highest_prob, aligned_class)\n",
    "        \n",
    "print(final_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"predictions.csv\", \"w\") as f:\n",
    "    f.write(\"ImageId,PredictedClass\")\n",
    "    for idx, label in enumerate(final_classes):\n",
    "        f.write(\"\\n{0},{1}\".format(idx, label))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
