{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "This notebook creates 2 convolutional neural networks, 1 for aligned images and 1 for unaligned raw images.\n",
    "Predictions are then based on the network that provides the higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "seed = 3244\n",
    "np.random.seed(seed)\n",
    "\n",
    "h = 50  # height of image\n",
    "w = 37  # width of image\n",
    "aligned_h = h\n",
    "aligned_w = h\n",
    "\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data used for unaligned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load original data\n",
    "X = np.load('X_train.npy') # (996, 1850)\n",
    "y = np.load('y_train.npy') # (996, 1)\n",
    "\n",
    "# Split into training and validation set\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Load generated data for training set\n",
    "X_generated_train = np.load('X_train_generated_train.npy')\n",
    "y_generated_train = np.load('y_train_generated_train.npy')\n",
    "\n",
    "# Add generated data for training set to original training set\n",
    "X_train = np.concatenate([X_train, X_generated_train])\n",
    "y_train_raw = np.concatenate([y_train_raw, y_generated_train])\n",
    "\n",
    "# Load generated data for validation set\n",
    "X_generated_test = np.load('X_train_generated_test.npy')\n",
    "y_generated_test = np.load('y_train_generated_test.npy')\n",
    "\n",
    "# Concatenate with generated data for training set to get all generated data\n",
    "X_generated = np.concatenate([X_generated_train, X_generated_test])\n",
    "y_generated = np.concatenate([y_generated_train, y_generated_test])\n",
    "\n",
    "# Add all generated data to full training set\n",
    "X = np.concatenate([X, X_generated])\n",
    "y = np.concatenate([y, y_generated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data used for aligned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load original data\n",
    "X_aligned = np.load('X_train_aligned.npy')\n",
    "y_aligned = np.load('y_train_aligned.npy')\n",
    "\n",
    "# Split into training and validation set\n",
    "X_train_aligned, X_test_aligned, y_train_aligned_raw, y_test_aligned_raw = train_test_split(X_aligned, y_aligned, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Load generated data for training set\n",
    "X_generated_train_aligned = np.load('X_train_generated_train_aligned.npy')\n",
    "y_generated_train_aligned = np.load('y_train_generated_train_aligned.npy')\n",
    "\n",
    "# Add generated data for training set to original training set\n",
    "X_train_aligned = np.concatenate([X_train_aligned, X_generated_train_aligned])\n",
    "y_train_aligned_raw = np.concatenate([y_train_aligned_raw, y_generated_train_aligned])\n",
    "\n",
    "# Load generated data for validation set\n",
    "X_generated_test_aligned = np.load('X_train_generated_test_aligned.npy')\n",
    "y_generated_test_aligned = np.load('y_train_generated_test_aligned.npy')\n",
    "\n",
    "# Concatenate with generated data for training set to get all generated data\n",
    "X_generated_aligned = np.concatenate([X_generated_train_aligned, X_generated_test_aligned])\n",
    "y_generated_aligned = np.concatenate([y_generated_train_aligned, y_generated_test_aligned])\n",
    "\n",
    "# Add all generated data to full training set\n",
    "X_aligned = np.concatenate([X_aligned, X_generated_aligned])\n",
    "y_aligned = np.concatenate([y_aligned, y_generated_aligned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shapeData(data, h=h, w=w):\n",
    "    return data.reshape(data.shape[0], 1, h, w).astype('float32')\n",
    "\n",
    "def normalize(data):\n",
    "    return data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = normalize(shapeData(X))\n",
    "\n",
    "X_train = normalize(shapeData(X_train))\n",
    "X_test = normalize(shapeData(X_test))\n",
    "\n",
    "X_train_aligned = normalize(shapeData(X_train_aligned, h=aligned_h, w=aligned_w))\n",
    "X_test_aligned = normalize(shapeData(X_test_aligned, h=aligned_h, w=aligned_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One hot encode outputs, this is required for the CNN\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train_raw)\n",
    "y_test = np_utils.to_categorical(y_test_raw)\n",
    "\n",
    "y_train_aligned = np_utils.to_categorical(y_train_aligned_raw)\n",
    "y_test_aligned = np_utils.to_categorical(y_test_aligned_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"Baseline model with 1 convolution, 1 max pooling and 2 fully connected layers\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters = 32  # number of convolutional filters to use\n",
    "pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "kernel_size = (5, 5)  # convolution kernel size\n",
    "\n",
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model2():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Note: Keras does automatic shape inference.\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model3():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1],\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, h, w)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model4():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1), input_shape=(1, h, w)))\n",
    "    model.add(Convolution2D(64, 3, 3,  activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation=\"relu\")) # 4096\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def model5(h=h, w=w):\n",
    "    \"\"\"Final configuration of the convolutional neural network that we found to perform the best\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, input_shape=(1, h, w), border_mode='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='valid', activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network based on the raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = baseline_model()\n",
    "# model = model1()\n",
    "# model = model2()\n",
    "# model = model3()\n",
    "# model = model4()\n",
    "model = model5()\n",
    "\n",
    "nb_epoch = 40\n",
    "batch_size = 50\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=batch_size, \n",
    "          verbose=1)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "f1_score(y_test_raw, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_raw, y_pred)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a network based on the aligned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model5(h=aligned_h, w=aligned_w)\n",
    "\n",
    "model.fit(X_train_aligned, y_train_aligned, \n",
    "          validation_data=(X_test_aligned, y_test_aligned),\n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=batch_size, \n",
    "          verbose=1)\n",
    "\n",
    "y_pred_aligned = model.predict_classes(X_test_aligned)\n",
    "f1_score(y_test_aligned_raw, y_pred_aligned, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_aligned_raw, y_pred_aligned)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a full model on the entire given dataset\n",
    "This includes generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_model = model5()\n",
    "full_model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a full model on the aligned images derived from the entire given dataset\n",
    "This includes generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_aligned = normalize(shapeData(X_aligned, h=aligned_h, w=aligned_w))\n",
    "y_aligned = np_utils.to_categorical(y_aligned)\n",
    "\n",
    "full_model_aligned = model5(h=aligned_h, w=aligned_w)\n",
    "full_model_aligned.fit(X_aligned, y_aligned, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the above 2 models to predict the labels of the given test set\n",
    "The test set with its images aligned are also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_given = normalize(shapeData(np.load('X_test.npy')))\n",
    "X_test_given_aligned = normalize(shapeData(np.load('X_test_aligned.npy'), h=aligned_h, w=aligned_w))\n",
    "\n",
    "classes_unaligned = full_model.predict_classes(X_test_given)\n",
    "classes_aligned = full_model_aligned.predict_classes(X_test_given_aligned)\n",
    "\n",
    "prob_unaligned = full_model.predict_proba(X_test_given)\n",
    "prob_aligned = full_model_aligned.predict_proba(X_test_given_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes_unaligned)\n",
    "print(classes_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieved from aligning the images, these are the indices of images where no face was detected\n",
    "idx_no_face = [25, 85, 104, 106, 125, 131, 180, 202, 211, 233, 238, 244, 279, 283, 304, 309]\n",
    "\n",
    "updated_classes = classes_aligned.tolist()\n",
    "updated_prob = prob_aligned.tolist()\n",
    "\n",
    "# Insert placeholder \"None\" to indicate that no class was derived for images with no face detected\n",
    "for i in idx_no_face:\n",
    "    updated_classes.insert(i, None)\n",
    "    updated_prob.insert(i, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the final class labels from an ensemble of the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_max(lst):\n",
    "    if lst:\n",
    "        return max(lst), lst.index(max(lst))\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "final_classes = []\n",
    "\n",
    "# Find the predicted class with the highest probability from the 2 model predictions\n",
    "for idx, (unaligned_prob, aligned_prob) in enumerate(zip(prob_unaligned, updated_prob)):\n",
    "    unaligned_highest_prob, unaligned_class = get_max(unaligned_prob.tolist())\n",
    "    aligned_highest_prob, aligned_class = get_max(aligned_prob)\n",
    "    \n",
    "    if aligned_highest_prob is None or unaligned_highest_prob > aligned_highest_prob:\n",
    "        final_classes.append(unaligned_class)\n",
    "    elif aligned_highest_prob >= unaligned_highest_prob:\n",
    "        final_classes.append(aligned_class)\n",
    "    else:\n",
    "        print(idx, unaligned_highest_prob, unaligned_class, aligned_highest_prob, aligned_class)\n",
    "        \n",
    "print(final_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"predictions.csv\", \"w\") as f:\n",
    "    f.write(\"ImageId,PredictedClass\")\n",
    "    for idx, label in enumerate(final_classes):\n",
    "        f.write(\"\\n{0},{1}\".format(idx, label))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
