{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing and Augmentation\n",
    "\n",
    "This notebook handles 2 aspects of preparing the data:\n",
    "1. Preprocessing of images by finding the face in each image and performing affine transformations to normalize them\n",
    "2. Using affine transformations to generate more images based on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    \"\"\"Helper method to show a greyscale image.\"\"\"\n",
    "    plt.imshow(image, cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The code here is adapted from the following 2 sources.\n",
    "# https://github.com/cmusatyalab/openface/blob/master/openface/align_dlib.py\n",
    "# https://gist.github.com/ageitgey/82d0ea0fdb56dc93cb9b716e7ceb364b\n",
    "\n",
    "TEMPLATE = np.float32([\n",
    "    (0.0792396913815, 0.339223741112), (0.0829219487236, 0.456955367943),\n",
    "    (0.0967927109165, 0.575648016728), (0.122141515615, 0.691921601066),\n",
    "    (0.168687863544, 0.800341263616), (0.239789390707, 0.895732504778),\n",
    "    (0.325662452515, 0.977068762493), (0.422318282013, 1.04329000149),\n",
    "    (0.531777802068, 1.06080371126), (0.641296298053, 1.03981924107),\n",
    "    (0.738105872266, 0.972268833998), (0.824444363295, 0.889624082279),\n",
    "    (0.894792677532, 0.792494155836), (0.939395486253, 0.681546643421),\n",
    "    (0.96111933829, 0.562238253072), (0.970579841181, 0.441758925744),\n",
    "    (0.971193274221, 0.322118743967), (0.163846223133, 0.249151738053),\n",
    "    (0.21780354657, 0.204255863861), (0.291299351124, 0.192367318323),\n",
    "    (0.367460241458, 0.203582210627), (0.4392945113, 0.233135599851),\n",
    "    (0.586445962425, 0.228141644834), (0.660152671635, 0.195923841854),\n",
    "    (0.737466449096, 0.182360984545), (0.813236546239, 0.192828009114),\n",
    "    (0.8707571886, 0.235293377042), (0.51534533827, 0.31863546193),\n",
    "    (0.516221448289, 0.396200446263), (0.517118861835, 0.473797687758),\n",
    "    (0.51816430343, 0.553157797772), (0.433701156035, 0.604054457668),\n",
    "    (0.475501237769, 0.62076344024), (0.520712933176, 0.634268222208),\n",
    "    (0.565874114041, 0.618796581487), (0.607054002672, 0.60157671656),\n",
    "    (0.252418718401, 0.331052263829), (0.298663015648, 0.302646354002),\n",
    "    (0.355749724218, 0.303020650651), (0.403718978315, 0.33867711083),\n",
    "    (0.352507175597, 0.349987615384), (0.296791759886, 0.350478978225),\n",
    "    (0.631326076346, 0.334136672344), (0.679073381078, 0.29645404267),\n",
    "    (0.73597236153, 0.294721285802), (0.782865376271, 0.321305281656),\n",
    "    (0.740312274764, 0.341849376713), (0.68499850091, 0.343734332172),\n",
    "    (0.353167761422, 0.746189164237), (0.414587777921, 0.719053835073),\n",
    "    (0.477677654595, 0.706835892494), (0.522732900812, 0.717092275768),\n",
    "    (0.569832064287, 0.705414478982), (0.635195811927, 0.71565572516),\n",
    "    (0.69951672331, 0.739419187253), (0.639447159575, 0.805236879972),\n",
    "    (0.576410514055, 0.835436670169), (0.525398405766, 0.841706377792),\n",
    "    (0.47641545769, 0.837505914975), (0.41379548902, 0.810045601727),\n",
    "    (0.380084785646, 0.749979603086), (0.477955996282, 0.74513234612),\n",
    "    (0.523389793327, 0.748924302636), (0.571057789237, 0.74332894691),\n",
    "    (0.672409137852, 0.744177032192), (0.572539621444, 0.776609286626),\n",
    "    (0.5240106503, 0.783370783245), (0.477561227414, 0.778476346951)])\n",
    "\n",
    "TPL_MIN, TPL_MAX = np.min(TEMPLATE, axis=0), np.max(TEMPLATE, axis=0)\n",
    "MINMAX_TEMPLATE = (TEMPLATE - TPL_MIN) / (TPL_MAX - TPL_MIN)\n",
    "\n",
    "OUTER_EYES_AND_NOSE = [36, 45, 33]\n",
    "np_landmark_indices = np.array(OUTER_EYES_AND_NOSE)\n",
    "\n",
    "# The required pre-trained face detection model can be downloaded here:\n",
    "# http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "predictor_model = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Initialise the predictor and detector from dlib\n",
    "predictor = dlib.shape_predictor(predictor_model)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "def get_aligned_faces(image, img_dim=50):\n",
    "    \"\"\"\n",
    "    Get a list of faces found in the given image,\n",
    "    if no face was found, returns an empty list\n",
    "    \"\"\"\n",
    "    detected_faces = detector(image, 1)\n",
    "    aligned_faces = []\n",
    "    \n",
    "    for i, face_rect in enumerate(detected_faces):\n",
    "#         print(\"Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\"\n",
    "#               .format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n",
    "        landmarks = predictor(image, face_rect)\n",
    "\n",
    "        np_landmarks = np.float32(list(map(lambda p: (p.x, p.y), landmarks.parts())))\n",
    "        \n",
    "        H = cv2.getAffineTransform(np_landmarks[np_landmark_indices],\n",
    "                                   img_dim * MINMAX_TEMPLATE[np_landmark_indices])\n",
    "    \n",
    "        thumbnail = cv2.warpAffine(image, H, (img_dim, img_dim))\n",
    "        aligned_faces.append(thumbnail)\n",
    "        \n",
    "    return aligned_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align `X_train` images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load('X_train.npy')\n",
    "labels = np.load('y_train.npy')\n",
    "\n",
    "# Reshape the input images and convert them to integers, the alignment of faces requires integer values\n",
    "images_reshaped = images.reshape(images.shape[0], 50, 37).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aligned_images = []\n",
    "filtered_labels = []\n",
    "\n",
    "# Get all aligned images from all given X_train images\n",
    "for idx, image in enumerate(images_reshaped):\n",
    "    faces = get_aligned_faces(image)\n",
    "    if faces:\n",
    "        aligned_images.append(faces[0])\n",
    "        filtered_labels.append(labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the aligned images\n",
    "np_aligned_images = np.array(aligned_images).reshape(len(aligned_images), 50*50)\n",
    "np.save(\"X_train_aligned.npy\", np_aligned_images)\n",
    "np.save(\"y_train_aligned.npy\", np.array(filtered_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align `X_test` images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images = np.load('X_test.npy')\n",
    "test_images_reshaped = test_images.reshape(test_images.shape[0], 50, 37).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_test_images = []\n",
    "missing_idx = []  # Test images where no face was found are handled differently, as stated in the README.\n",
    "\n",
    "for idx, image in enumerate(test_images_reshaped):\n",
    "    faces = get_aligned_faces(image)\n",
    "    if faces:\n",
    "        aligned_test_images.append(faces[0])\n",
    "    else:\n",
    "        missing_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_aligned_test_images = np.array(aligned_test_images).reshape(len(aligned_test_images), 50*50)\n",
    "np.save(\"X_test_aligned.npy\", np_aligned_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 85, 104, 106, 125, 131, 180, 202, 211, 233, 238, 244, 279, 283, 304, 309]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training dataset\n",
    "\n",
    "This section generates more images by performing randomised affine transformations to the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = 50\n",
    "w = 37\n",
    "\n",
    "def shapeData(data, h=h, w=w):\n",
    "    return data.reshape(data.shape[0], 1, h, w).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split `X_train` set into `X_train_train` (training set) and `X_train_test` (validation set for model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 3244\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment `X_train_train` images (to be included in unaligned training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_reshaped_float = shapeData(images_train)\n",
    "\n",
    "# Create a generator that performs shearing, zooming and/or rotation on the given images\n",
    "datagen = ImageDataGenerator(shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             rotation_range=10)\n",
    "datagen.fit(images_reshaped_float)\n",
    "\n",
    "new_data = []  # store new images\n",
    "new_label = []  # store the label of new images\n",
    "number_of_batches = 800\n",
    "batches = 0\n",
    "\n",
    "for X_batch, Y_batch in datagen.flow(images_reshaped_float, labels_train, batch_size=number_of_batches):\n",
    "    image = X_batch[0][0]\n",
    "    label = Y_batch[0]\n",
    "    \n",
    "    faces = get_aligned_faces(image.astype('uint8'))\n",
    "    if not faces:  # If no face was found, ignore the generated image\n",
    "        continue\n",
    "        \n",
    "    new_data.append(image.flatten())\n",
    "    new_label.append(label)\n",
    "    batches += 1\n",
    "    if batches >= number_of_batches:\n",
    "        break\n",
    "\n",
    "np.save(\"X_train_generated_train.npy\", np.array(new_data))\n",
    "np.save(\"y_train_generated_train.npy\", np.array(new_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment `X_train_test` images (not used for validation but added to full training set after model selection to train full unaligned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_reshaped_float = shapeData(images_test)\n",
    "\n",
    "datagen = ImageDataGenerator(shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             rotation_range=10)\n",
    "datagen.fit(images_reshaped_float)\n",
    "\n",
    "new_data = []  # store new images\n",
    "new_label = []  # store the label of new images\n",
    "number_of_batches = 200\n",
    "batches = 0\n",
    "\n",
    "for X_batch, Y_batch in datagen.flow(images_reshaped_float, labels_test, batch_size=number_of_batches):\n",
    "    image = X_batch[0][0]\n",
    "    label = Y_batch[0]\n",
    "    \n",
    "    faces = get_aligned_faces(image.astype('uint8'))\n",
    "    if not faces:\n",
    "        continue\n",
    "        \n",
    "    new_data.append(image.flatten())\n",
    "    new_label.append(label)\n",
    "    batches += 1\n",
    "    if batches >= number_of_batches:\n",
    "        break\n",
    "\n",
    "np.save(\"X_train_generated_test.npy\", np.array(new_data))\n",
    "np.save(\"y_train_generated_test.npy\", np.array(new_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align `X_train_train` images (to be included in aligned training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = np.load('X_train_generated_train.npy')\n",
    "labels = np.load('y_train_generated_train.npy')\n",
    "images_reshaped = images.reshape(images.shape[0], 50, 37).astype('uint8')\n",
    "\n",
    "aligned_images = []\n",
    "filtered_labels = []\n",
    "for idx, image in enumerate(images_reshaped):\n",
    "    faces = get_aligned_faces(image)\n",
    "    if not faces:\n",
    "        continue\n",
    "    aligned_images.append(faces[0])\n",
    "    filtered_labels.append(labels[idx])\n",
    "\n",
    "np_aligned_images = np.array(aligned_images).reshape(len(aligned_images), 50*50)\n",
    "np.save(\"X_train_generated_train_aligned.npy\", np_aligned_images)\n",
    "np.save(\"y_train_generated_train_aligned.npy\", np.array(filtered_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align `X_train_test` images (not used for validation but added to full training set after model selection to train full aligned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load('X_train_generated_test.npy')\n",
    "labels = np.load('y_train_generated_test.npy')\n",
    "images_reshaped = images.reshape(images.shape[0], 50, 37).astype('uint8')\n",
    "\n",
    "aligned_images = []\n",
    "filtered_labels = []\n",
    "for idx, image in enumerate(images_reshaped):\n",
    "    faces = get_aligned_faces(image)\n",
    "    if not faces:\n",
    "        continue\n",
    "    aligned_images.append(faces[0])\n",
    "    filtered_labels.append(labels[idx])\n",
    "\n",
    "np_aligned_images = np.array(aligned_images).reshape(len(aligned_images), 50*50)\n",
    "np.save(\"X_train_generated_test_aligned.npy\", np_aligned_images)\n",
    "np.save(\"y_train_generated_test_aligned.npy\", np.array(filtered_labels))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
