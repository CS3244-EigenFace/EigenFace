{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 3244\n",
    "np.random.seed(seed)\n",
    "\n",
    "h = 50  # height of image\n",
    "w = 37  # width of image\n",
    "num_pixels = h * w\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load('X_train.npy') # (996, 1850)\n",
    "y = np.load('y_train.npy') # (996, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shapeData(data, h=50, w=37):\n",
    "    return data.reshape(data.shape[0], 1, h, w).astype('float32')\n",
    "\n",
    "X_train = shapeData(X_train)\n",
    "X_test = shapeData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data / 255\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters = 32  # number of convolutional filters to use\n",
    "pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "kernel_size = (5, 5)  # convolution kernel size\n",
    "\n",
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model2():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Note: Keras does automatic shape inference.\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model3():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1],\n",
    "                            border_mode='valid',\n",
    "                            input_shape=(1, h, w)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(num_filters, kernel_size[0], kernel_size[1]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 772 samples, validate on 194 samples\n",
      "Epoch 1/40\n",
      "772/772 [==============================] - 4s - loss: 1.7833 - acc: 0.3368 - val_loss: 1.6628 - val_acc: 0.4278\n",
      "Epoch 2/40\n",
      "772/772 [==============================] - 4s - loss: 1.6582 - acc: 0.4080 - val_loss: 1.5848 - val_acc: 0.4278\n",
      "Epoch 3/40\n",
      "772/772 [==============================] - 4s - loss: 1.5709 - acc: 0.4262 - val_loss: 1.5752 - val_acc: 0.5773\n",
      "Epoch 4/40\n",
      "772/772 [==============================] - 4s - loss: 1.4563 - acc: 0.4961 - val_loss: 1.3636 - val_acc: 0.4794\n",
      "Epoch 5/40\n",
      "772/772 [==============================] - 4s - loss: 1.2817 - acc: 0.5415 - val_loss: 1.1947 - val_acc: 0.5928\n",
      "Epoch 6/40\n",
      "772/772 [==============================] - 4s - loss: 1.0957 - acc: 0.6244 - val_loss: 1.0734 - val_acc: 0.6134\n",
      "Epoch 7/40\n",
      "772/772 [==============================] - 4s - loss: 0.9047 - acc: 0.7060 - val_loss: 0.9217 - val_acc: 0.6392\n",
      "Epoch 8/40\n",
      "772/772 [==============================] - 6s - loss: 0.7526 - acc: 0.7630 - val_loss: 0.8533 - val_acc: 0.6804\n",
      "Epoch 9/40\n",
      "772/772 [==============================] - 8s - loss: 0.6414 - acc: 0.8212 - val_loss: 0.8548 - val_acc: 0.7010\n",
      "Epoch 10/40\n",
      "772/772 [==============================] - 8s - loss: 0.5795 - acc: 0.8394 - val_loss: 0.6465 - val_acc: 0.7887\n",
      "Epoch 11/40\n",
      "772/772 [==============================] - 8s - loss: 0.4576 - acc: 0.8653 - val_loss: 0.6761 - val_acc: 0.8093\n",
      "Epoch 12/40\n",
      "772/772 [==============================] - 8s - loss: 0.4066 - acc: 0.8977 - val_loss: 0.5829 - val_acc: 0.8093\n",
      "Epoch 13/40\n",
      "772/772 [==============================] - 9s - loss: 0.3492 - acc: 0.9145 - val_loss: 0.5493 - val_acc: 0.8299\n",
      "Epoch 14/40\n",
      "772/772 [==============================] - 9s - loss: 0.3316 - acc: 0.9054 - val_loss: 0.5699 - val_acc: 0.8299\n",
      "Epoch 15/40\n",
      "772/772 [==============================] - 9s - loss: 0.2788 - acc: 0.9404 - val_loss: 0.5071 - val_acc: 0.8454\n",
      "Epoch 16/40\n",
      "772/772 [==============================] - 8s - loss: 0.2314 - acc: 0.9495 - val_loss: 0.4897 - val_acc: 0.8454\n",
      "Epoch 17/40\n",
      "772/772 [==============================] - 8s - loss: 0.1929 - acc: 0.9598 - val_loss: 0.5000 - val_acc: 0.8608\n",
      "Epoch 18/40\n",
      "772/772 [==============================] - 8s - loss: 0.1754 - acc: 0.9702 - val_loss: 0.5337 - val_acc: 0.8351\n",
      "Epoch 19/40\n",
      "772/772 [==============================] - 8s - loss: 0.1496 - acc: 0.9754 - val_loss: 0.5020 - val_acc: 0.8454\n",
      "Epoch 20/40\n",
      "772/772 [==============================] - 8s - loss: 0.1433 - acc: 0.9741 - val_loss: 0.5144 - val_acc: 0.8557\n",
      "Epoch 21/40\n",
      "772/772 [==============================] - 8s - loss: 0.1192 - acc: 0.9806 - val_loss: 0.5046 - val_acc: 0.8557\n",
      "Epoch 22/40\n",
      "772/772 [==============================] - 9s - loss: 0.1048 - acc: 0.9883 - val_loss: 0.5602 - val_acc: 0.8402\n",
      "Epoch 23/40\n",
      "772/772 [==============================] - 9s - loss: 0.0977 - acc: 0.9845 - val_loss: 0.5167 - val_acc: 0.8247\n",
      "Epoch 24/40\n",
      "772/772 [==============================] - 9s - loss: 0.0814 - acc: 0.9909 - val_loss: 0.5050 - val_acc: 0.8557\n",
      "Epoch 25/40\n",
      "772/772 [==============================] - 8s - loss: 0.0829 - acc: 0.9922 - val_loss: 0.4646 - val_acc: 0.8814\n",
      "Epoch 26/40\n",
      "772/772 [==============================] - 8s - loss: 0.0758 - acc: 0.9870 - val_loss: 0.6044 - val_acc: 0.8299\n",
      "Epoch 27/40\n",
      "772/772 [==============================] - 9s - loss: 0.0667 - acc: 0.9987 - val_loss: 0.4989 - val_acc: 0.8608\n",
      "Epoch 28/40\n",
      "772/772 [==============================] - 8s - loss: 0.0540 - acc: 0.9961 - val_loss: 0.5206 - val_acc: 0.8505\n",
      "Epoch 29/40\n",
      "772/772 [==============================] - 8s - loss: 0.0476 - acc: 0.9987 - val_loss: 0.5231 - val_acc: 0.8814\n",
      "Epoch 30/40\n",
      "772/772 [==============================] - 8s - loss: 0.0404 - acc: 0.9987 - val_loss: 0.5303 - val_acc: 0.8557\n",
      "Epoch 31/40\n",
      "772/772 [==============================] - 8s - loss: 0.0398 - acc: 0.9974 - val_loss: 0.4923 - val_acc: 0.8711\n",
      "Epoch 32/40\n",
      "772/772 [==============================] - 8s - loss: 0.0343 - acc: 0.9987 - val_loss: 0.4852 - val_acc: 0.8814\n",
      "Epoch 33/40\n",
      "772/772 [==============================] - 8s - loss: 0.0286 - acc: 0.9987 - val_loss: 0.4817 - val_acc: 0.8557\n",
      "Epoch 34/40\n",
      "772/772 [==============================] - 8s - loss: 0.0269 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.8763\n",
      "Epoch 35/40\n",
      "772/772 [==============================] - 8s - loss: 0.0237 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8608\n",
      "Epoch 36/40\n",
      "772/772 [==============================] - 8s - loss: 0.0228 - acc: 1.0000 - val_loss: 0.4969 - val_acc: 0.8711\n",
      "Epoch 37/40\n",
      "772/772 [==============================] - 10s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.8711\n",
      "Epoch 38/40\n",
      "772/772 [==============================] - 9s - loss: 0.0223 - acc: 1.0000 - val_loss: 0.5241 - val_acc: 0.8711\n",
      "Epoch 39/40\n",
      "772/772 [==============================] - 9s - loss: 0.0185 - acc: 0.9987 - val_loss: 0.5197 - val_acc: 0.8660\n",
      "Epoch 40/40\n",
      "772/772 [==============================] - 9s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.8763\n",
      "Model accuracy: 87.63%\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "# model = model1()\n",
    "# model = model2()\n",
    "# model = model3()\n",
    "\n",
    "nb_epoch = 40\n",
    "batch_size = 50\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=batch_size, \n",
    "          verbose=1)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
